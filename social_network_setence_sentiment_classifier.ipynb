{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 句子情感分类 - 判断社交网络中的句子的情感倾向\n",
    "#### Data Download: https://www.lintcode.com/ai/UMICH_Sentiment_Analysis/data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from keras.preprocessing import sequence\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok brokeback mountain is such a horrible movie.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brokeback Mountain was so awesome.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friday hung out with kelsie and we went and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am going to start reading the Harry Potter s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it just me, or does Harry Potter suck?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0    Ok brokeback mountain is such a horrible movie.      0\n",
       "1                 Brokeback Mountain was so awesome.      1\n",
       "2  friday hung out with kelsie and we went and sa...      0\n",
       "3  I am going to start reading the Harry Potter s...      1\n",
       "4       Is it just me, or does Harry Potter suck?...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I liked the first \" Mission Impossible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love Harry Potter..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not because I hate Harry Potter, but because I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story of Harry Potter is a deep and profou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The complaints I've seen about the \" Vito-bein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0            I liked the first \" Mission Impossible.\n",
       "1                              I love Harry Potter..\n",
       "2  Not because I hate Harry Potter, but because I...\n",
       "3  the story of Harry Potter is a deep and profou...\n",
       "4  The complaints I've seen about the \" Vito-bein..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668\n"
     ]
    }
   ],
   "source": [
    "num_recs = len(train_data) # number of total train sentences\n",
    "print(num_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data) # number of total test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_10 = train_data.head(1)\n",
    "test_data_10 = test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/s4467575/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 0 # maximum sentence length\n",
    "word_freqs = collections.Counter() # word frequency\n",
    "\n",
    "# Note: train， test 数据都要考虑到\n",
    "for data in [train_data, test_data]: # 相当于把train test 一起同时处理了，否则需要两个for loop分别处理train 和test\n",
    "    for index, row in data.iterrows(): # iterae each row\n",
    "        '''\n",
    "            为了使用nltk.word_tokenize, 需要先run \"nltk.download('punkt')\" command to download 语料库\n",
    "            nltk.word_tokenize就是把句子分割成单词：\n",
    "            e.g. \"Ok brokeback mountain is such a horrible movie.\" ==>\n",
    "                  ['ok', 'brokeback', 'mountain', 'is', 'such', 'a', 'horrible', 'movie', '.']\n",
    "            \n",
    "            因为train  data 里的 有lable column, 所以row['sentence'] 表示只处理\"sentence\" column\n",
    "            \n",
    "        '''\n",
    "        words = nltk.word_tokenize(row['sentence'].lower())\n",
    "        if (len(words) > maxlen):\n",
    "            maxlen = len(words)\n",
    "        for word in words:\n",
    "            word_freqs[word] += 1\n",
    "\n",
    "# word_freqs: dict type: (word, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(word_freqs))\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 2300 # number of unique words\n",
    "MAX_SENTENCE_LENGTH = maxlen # maximum sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = MAX_FEATURES + 2 # two more extra special words \"PAD\", \"UNK\"\n",
    "\n",
    "\"\"\"\n",
    "    i: index, x: ('i', 4705), x[0]: i (即表示实际的word)\n",
    "    本来 i就是表示index的意思， 只不过 0， 1 预留给了PAD, UNK特殊字符，其他所有的word的index都往后顺移2位\n",
    "\"\"\"\n",
    "word2index = {x[0]: i+2 for i, x in enumerate(word_freqs.most_common(MAX_FEATURES))} # word2index: (word, index), from most to least\n",
    "# word_freqs: (word, count)\n",
    "\n",
    "word2index[\"PAD\"] = 0\n",
    "word2index[\"UNK\"] = 1\n",
    "\n",
    "index2word = {v:k for k, v in word2index.items()} # word2index: (index, word), from most to least\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.empty((num_recs, ), dtype=list) # num_recs: number of total train sentences\n",
    "data_y = np.zeros((num_recs, ))\n",
    "\n",
    "#把train_data 每一句话 都split 成word,让后把word -> 对应的index\n",
    "for i, (index, row) in enumerate(train_data.iterrows()):\n",
    "    words = nltk.word_tokenize(row['sentence'].lower())\n",
    "    seqs = []\n",
    "    for word in words:\n",
    "        seqs.append(word2index.get(word, word2index['UNK']))\n",
    "    data_X[i] = seqs\n",
    "    data_y[i] = int(row['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94  11  13  17 143  18 126  26   4   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [ 11  13  19  33  22   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [166 228  53  47 229   6  44 108   6 114   5  10   9  12  32   7   7   7\n",
      "    7   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "(5668, 42)\n"
     ]
    }
   ],
   "source": [
    "# padding  把train_data里长度不一样的句子padding成一样长的，以最长的句子为标准， 不够长的在末尾补<PAD>\n",
    "data_X_in = sequence.pad_sequences(data_X, padding='post', value=word2index['PAD'], maxlen=MAX_SENTENCE_LENGTH)\n",
    "print(data_X_in[:3])\n",
    "print(data_X_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.565279\n",
       "0.0    0.434721\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data_y).value_counts() / len(data_y)  # 数据平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(data_X_in), batch_size):\n",
    "            if i + batch_size < len(data_X_in):\n",
    "                # [len(i) for i in data_X[i:i + batch_size]] 每个句子实际长度\n",
    "                yield data_X_in[i:i + batch_size], data_y[i:i + batch_size], [len(i) for i in data_X[i:i + batch_size]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Part - 可参考text_classify_basic 因为任务性质差不多，都是分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "embedding_size = 16 # 就是词的embedding table 的列数， 也就是每个单词就会变成 1 * 100 的矩阵\n",
    "vocab_size = MAX_FEATURES + 2\n",
    "num_units = 16\n",
    "NUM_EPOCHS = 16\n",
    "\"\"\"\n",
    "    num_units = 16 Hyper parameter. 是隐变量c的维度. 也就是每个RNN cell 的输出维度\n",
    "    Note: \n",
    "        RNN NMT 结构中，左边endocer公用一个RNN(虽然结构图里画了3个box,其实就是一个共享权重的RNN)，同理右半边decoder网络也是。\n",
    "        但是左边 和右边 的两个RNN 并不共享网络权重参数\n",
    "\n",
    "    在text_classfify任务的的时候，老师课上解释： RNN->S1->RNN->S2...这里的16就是就是S1的大小，也就是hidden unit memory 的大小\n",
    "    16个float -> 50 * 32bit (i.e. 50 * 4字节)\n",
    "   \n",
    "    在LSTM里：相当于Ct(长期记忆)和Ht（短期记忆）都是num_unit个浮点数， 也就是memory size. 在标准的RNN里就是是S1, S2 等这些状态的memeory size. \n",
    "\n",
    "\"\"\"\n",
    "losses = []\n",
    "beginning_lr = 0.1\n",
    "gen = data_generator(batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\"\"\"\n",
    "    allow_soft_placement=True, config.gpu_options.allow_growth = True\n",
    "    上面两句作用：可以动态分配GPU\n",
    "\"\"\"\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "with tf.device('/gpu:0'): # gpu:0表示gpu编号\n",
    "    # 下面几行初始化后变量和 seq2seq_basic 里类似\n",
    "    initializer = tf.random_uniform_initializer(-0.08, 0.08)\n",
    "    tf.get_variable_scope().set_initializer(initializer)\n",
    "    x = tf.placeholder(\"int32\", [None, None])\n",
    "    y = tf.placeholder(\"int32\", [None])\n",
    "    x_len = tf.placeholder(\"int32\", [None])\n",
    "    \n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "    # embedding 和 text_classify_basic 里写法类似\n",
    "    # tf.get_variable(\"embedding_encoder\") 如果变量存在， 直接使用，如果没有该变量，就重新生成一个变量\n",
    "    embedding_encoder = tf.get_variable(\"embedding_encoder\", [vocab_size, embedding_size], dtype=tf.float32)\n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, x)\n",
    "    \n",
    "    # Build RNN cell\n",
    "    encoder_cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "    \n",
    "    encoder_cell = tf.contrib.rnn.DropoutWrapper(cell=encoder_cell, output_keep_prob=0.5)\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outputs: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "        encoder_cell, encoder_emb_inp,\n",
    "        sequence_length=x_len, time_major=False, dtype=tf.float32) \n",
    "        #x_len 是反应每个句子实际的长度（padding之前的），也就是data_generator返回的最后一个参数\n",
    "        # encoder_outputs 对应RNN网络右边top的每个输出\n",
    "    model_logistic = tf.layers.dense(encoder_state[0], 1)  # encoder_state[0] c 也就是长期记忆，    encoder_state[1] h\n",
    "    model_pred = tf.nn.sigmoid(model_logistic)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y, tf.float32), logits=tf.reshape(model_logistic,(-1,)))\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "outer_epoch:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/56 [00:00<00:12,  4.30it/s]\u001b[A\n",
      " 18%|█▊        | 10/56 [00:00<00:07,  6.02it/s]\u001b[A\n",
      " 34%|███▍      | 19/56 [00:00<00:04,  8.35it/s]\u001b[A\n",
      " 52%|█████▏    | 29/56 [00:00<00:02, 11.47it/s]\u001b[A\n",
      " 70%|██████▉   | 39/56 [00:00<00:01, 15.56it/s]\u001b[A\n",
      " 86%|████████▌ | 48/56 [00:00<00:00, 20.65it/s]\u001b[A\n",
      "57it [00:00, 26.81it/s]                        \u001b[A\n",
      "outer_epoch:   6%|▋         | 1/16 [00:00<00:13,  1.15it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 87.44it/s]\u001b[A\n",
      " 32%|███▏      | 18/56 [00:00<00:00, 86.47it/s]\u001b[A\n",
      " 48%|████▊     | 27/56 [00:00<00:00, 86.55it/s]\u001b[A\n",
      " 64%|██████▍   | 36/56 [00:00<00:00, 86.40it/s]\u001b[A\n",
      " 80%|████████  | 45/56 [00:00<00:00, 86.88it/s]\u001b[A\n",
      " 96%|█████████▋| 54/56 [00:00<00:00, 86.50it/s]\u001b[A\n",
      "outer_epoch:  12%|█▎        | 2/16 [00:01<00:11,  1.24it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 82.48it/s]\u001b[A\n",
      " 30%|███       | 17/56 [00:00<00:00, 81.04it/s]\u001b[A\n",
      " 46%|████▋     | 26/56 [00:00<00:00, 81.02it/s]\u001b[A\n",
      " 62%|██████▎   | 35/56 [00:00<00:00, 82.47it/s]\u001b[A\n",
      " 79%|███████▊  | 44/56 [00:00<00:00, 83.27it/s]\u001b[A\n",
      " 95%|█████████▍| 53/56 [00:00<00:00, 84.12it/s]\u001b[A\n",
      "outer_epoch:  19%|█▉        | 3/16 [00:02<00:10,  1.30it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 88.56it/s]\u001b[A\n",
      " 32%|███▏      | 18/56 [00:00<00:00, 86.95it/s]\u001b[A\n",
      " 46%|████▋     | 26/56 [00:00<00:00, 84.09it/s]\u001b[A\n",
      " 59%|█████▉    | 33/56 [00:00<00:00, 78.37it/s]\u001b[A\n",
      " 73%|███████▎  | 41/56 [00:00<00:00, 77.60it/s]\u001b[A\n",
      " 88%|████████▊ | 49/56 [00:00<00:00, 77.47it/s]\u001b[A\n",
      "outer_epoch:  25%|██▌       | 4/16 [00:02<00:09,  1.32it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 82.51it/s]\u001b[A\n",
      " 30%|███       | 17/56 [00:00<00:00, 81.33it/s]\u001b[A\n",
      " 46%|████▋     | 26/56 [00:00<00:00, 82.95it/s]\u001b[A\n",
      " 62%|██████▎   | 35/56 [00:00<00:00, 83.00it/s]\u001b[A\n",
      " 79%|███████▊  | 44/56 [00:00<00:00, 82.89it/s]\u001b[A\n",
      " 95%|█████████▍| 53/56 [00:00<00:00, 82.37it/s]\u001b[A\n",
      "outer_epoch:  31%|███▏      | 5/16 [00:03<00:08,  1.35it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 7/56 [00:00<00:00, 62.26it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 67.01it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 71.30it/s]\u001b[A\n",
      " 61%|██████    | 34/56 [00:00<00:00, 75.08it/s]\u001b[A\n",
      " 75%|███████▌  | 42/56 [00:00<00:00, 75.92it/s]\u001b[A\n",
      " 91%|█████████ | 51/56 [00:00<00:00, 78.04it/s]\u001b[A\n",
      "outer_epoch:  38%|███▊      | 6/16 [00:04<00:07,  1.36it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 79.89it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 78.38it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 79.89it/s]\u001b[A\n",
      " 61%|██████    | 34/56 [00:00<00:00, 80.80it/s]\u001b[A\n",
      " 77%|███████▋  | 43/56 [00:00<00:00, 81.97it/s]\u001b[A\n",
      " 93%|█████████▎| 52/56 [00:00<00:00, 82.57it/s]\u001b[A\n",
      "outer_epoch:  44%|████▍     | 7/16 [00:05<00:06,  1.38it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 86.18it/s]\u001b[A\n",
      " 30%|███       | 17/56 [00:00<00:00, 81.22it/s]\u001b[A\n",
      " 43%|████▎     | 24/56 [00:00<00:00, 74.48it/s]\u001b[A\n",
      " 57%|█████▋    | 32/56 [00:00<00:00, 73.51it/s]\u001b[A\n",
      " 73%|███████▎  | 41/56 [00:00<00:00, 76.06it/s]\u001b[A\n",
      " 89%|████████▉ | 50/56 [00:00<00:00, 78.09it/s]\u001b[A\n",
      "outer_epoch:  50%|█████     | 8/16 [00:05<00:05,  1.37it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 9/56 [00:00<00:00, 81.86it/s]\u001b[A\n",
      " 30%|███       | 17/56 [00:00<00:00, 81.17it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 80.25it/s]\u001b[A\n",
      " 61%|██████    | 34/56 [00:00<00:00, 80.93it/s]\u001b[A\n",
      " 75%|███████▌  | 42/56 [00:00<00:00, 80.27it/s]\u001b[A\n",
      " 91%|█████████ | 51/56 [00:00<00:00, 80.50it/s]\u001b[A\n",
      "outer_epoch:  56%|█████▋    | 9/16 [00:06<00:05,  1.38it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 79.71it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 79.10it/s]\u001b[A\n",
      " 43%|████▎     | 24/56 [00:00<00:00, 78.90it/s]\u001b[A\n",
      " 57%|█████▋    | 32/56 [00:00<00:00, 78.94it/s]\u001b[A\n",
      " 71%|███████▏  | 40/56 [00:00<00:00, 78.71it/s]\u001b[A\n",
      " 86%|████████▌ | 48/56 [00:00<00:00, 78.34it/s]\u001b[A\n",
      "57it [00:00, 79.43it/s]                        \u001b[A\n",
      "outer_epoch:  62%|██████▎   | 10/16 [00:07<00:04,  1.38it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 77.56it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 77.39it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 78.58it/s]\u001b[A\n",
      " 59%|█████▉    | 33/56 [00:00<00:00, 78.45it/s]\u001b[A\n",
      " 73%|███████▎  | 41/56 [00:00<00:00, 77.99it/s]\u001b[A\n",
      " 88%|████████▊ | 49/56 [00:00<00:00, 78.38it/s]\u001b[A\n",
      "outer_epoch:  69%|██████▉   | 11/16 [00:07<00:03,  1.38it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 77.78it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 77.90it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 78.61it/s]\u001b[A\n",
      " 59%|█████▉    | 33/56 [00:00<00:00, 78.42it/s]\u001b[A\n",
      " 73%|███████▎  | 41/56 [00:00<00:00, 76.19it/s]\u001b[A\n",
      " 86%|████████▌ | 48/56 [00:00<00:00, 74.01it/s]\u001b[A\n",
      " 98%|█████████▊| 55/56 [00:00<00:00, 72.59it/s]\u001b[A\n",
      "outer_epoch:  75%|███████▌  | 12/16 [00:08<00:02,  1.35it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 7/56 [00:00<00:00, 69.69it/s]\u001b[A\n",
      " 27%|██▋       | 15/56 [00:00<00:00, 71.46it/s]\u001b[A\n",
      " 43%|████▎     | 24/56 [00:00<00:00, 74.64it/s]\u001b[A\n",
      " 57%|█████▋    | 32/56 [00:00<00:00, 75.86it/s]\u001b[A\n",
      " 71%|███████▏  | 40/56 [00:00<00:00, 76.72it/s]\u001b[A\n",
      " 86%|████████▌ | 48/56 [00:00<00:00, 77.17it/s]\u001b[A\n",
      "100%|██████████| 56/56 [00:00<00:00, 76.43it/s]\u001b[A\n",
      "outer_epoch:  81%|████████▏ | 13/16 [00:09<00:02,  1.35it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 73.02it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 74.18it/s]\u001b[A\n",
      " 43%|████▎     | 24/56 [00:00<00:00, 75.31it/s]\u001b[A\n",
      " 57%|█████▋    | 32/56 [00:00<00:00, 76.28it/s]\u001b[A\n",
      " 71%|███████▏  | 40/56 [00:00<00:00, 76.97it/s]\u001b[A\n",
      " 86%|████████▌ | 48/56 [00:00<00:00, 77.09it/s]\u001b[A\n",
      "100%|██████████| 56/56 [00:00<00:00, 76.51it/s]\u001b[A\n",
      "outer_epoch:  88%|████████▊ | 14/16 [00:10<00:01,  1.35it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 73.89it/s]\u001b[A\n",
      " 29%|██▊       | 16/56 [00:00<00:00, 72.98it/s]\u001b[A\n",
      " 41%|████      | 23/56 [00:00<00:00, 71.38it/s]\u001b[A\n",
      " 55%|█████▌    | 31/56 [00:00<00:00, 72.35it/s]\u001b[A\n",
      " 70%|██████▉   | 39/56 [00:00<00:00, 73.32it/s]\u001b[A\n",
      " 84%|████████▍ | 47/56 [00:00<00:00, 73.89it/s]\u001b[A\n",
      " 96%|█████████▋| 54/56 [00:00<00:00, 70.96it/s]\u001b[A\n",
      "outer_epoch:  94%|█████████▍| 15/16 [00:11<00:00,  1.32it/s]\n",
      "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 8/56 [00:00<00:00, 79.13it/s]\u001b[A\n",
      " 30%|███       | 17/56 [00:00<00:00, 79.64it/s]\u001b[A\n",
      " 45%|████▍     | 25/56 [00:00<00:00, 77.86it/s]\u001b[A\n",
      " 57%|█████▋    | 32/56 [00:00<00:00, 74.83it/s]\u001b[A\n",
      " 73%|███████▎  | 41/56 [00:00<00:00, 76.57it/s]\u001b[A\n",
      " 88%|████████▊ | 49/56 [00:00<00:00, 76.36it/s]\u001b[A\n",
      "57it [00:00, 76.70it/s]                        \u001b[A\n",
      "outer_epoch: 100%|██████████| 16/16 [00:11<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for one_epoch in tqdm.trange(0, NUM_EPOCHS, desc='outer_epoch'):\n",
    "    for one_batch in tqdm.tqdm(range(0, len(data_X_in) ,batch_size), total=len(data_X_in) // batch_size):\n",
    "        batch_x, batch_y, batch_x_len = gen.__next__() # batch_x_len batch里 每个句子长度\n",
    "        batch_lr = beginning_lr \n",
    "        \n",
    "        _, batch_loss = session.run([optimizer, loss], feed_dict={\n",
    "            x: batch_x,\n",
    "            y: batch_y,\n",
    "            x_len: batch_x_len,\n",
    "            learning_rate: batch_lr,\n",
    "        })\n",
    "        losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c310c2978>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418\n"
     ]
    }
   ],
   "source": [
    "test_recs = len(test_data)\n",
    "print(test_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    words = nltk.word_tokenize(row['sentence'].lower()) # 每一行的 sentence column 里的句子分割成词\n",
    "    senttoken = [word2index.get(word, word2index['UNK']) for word in words]\n",
    "    test_X.append(senttoken)\n",
    "\n",
    "# test_X = sequence.pad_sequences(test_X, padding='post', value=word2index['PAD'], maxlen=MAX_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 122, 5, 115, 36, 20, 21, 4], [2, 16, 8, 50]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(senttoken):\n",
    "    inputx = np.asarray([senttoken])\n",
    "    inputx_len = np.asarray([len(senttoken)])\n",
    "    return session.run(model_pred, feed_dict={\n",
    "            x:inputx,\n",
    "            x_len:inputx_len,\n",
    "        })[0]\n",
    "\n",
    "logits = []\n",
    "for row in test_X:\n",
    "    logits.append(predict_result(row))\n",
    "    \n",
    "logits = pd.Series(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.9999784]\n",
       "1       [0.99853027]\n",
       "2    [1.6598815e-05]\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_percent = (pd.Series(data_y).value_counts() / len(data_y))[0]\n",
    "# n_num = int(n_percent * len(logits))\n",
    "# logits[logits.sort_values().index[:n_num]] = 0\n",
    "# logits[logits.sort_values().index[n_num:]] = 1\n",
    "\n",
    "logits = (logits > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1418, 2)\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAMES = ['sentence', 'label']\n",
    "df = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "df['sentence'] = test_data['sentence']\n",
    "ll = pd.Series(logits)\n",
    "df['label'] = ll.values\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  label\n",
      "0            I liked the first \" Mission Impossible.      1\n",
      "1                              I love Harry Potter..      1\n",
      "2  Not because I hate Harry Potter, but because I...      0\n",
      "3  the story of Harry Potter is a deep and profou...      1\n",
      "4  The complaints I've seen about the \" Vito-bein...      0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR, \"submission.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  label\n",
      "0            I liked the first \" Mission Impossible.      1\n",
      "1                              I love Harry Potter..      1\n",
      "2  Not because I hate Harry Potter, but because I...      0\n",
      "3  the story of Harry Potter is a deep and profou...      1\n",
      "4  The complaints I've seen about the \" Vito-bein...      0\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.read_csv(os.path.join(DATA_DIR, \"submission.csv\")) # 正确答案\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
